{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "spark2 = SparkSession.builder.appName('ml').getOrCreate()\n",
    "#Create a Spark Session\n",
    "SpSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"ml\") \\\n",
    "    .config(\"spark.executor.memory\", \"0.1g\") \\\n",
    "    .config(\"spark.cores.max\",\"2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/home/sushant/Projects/Spark_Project/temp\")\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "#Get the Spark Context from Spark Session    \n",
    "SpContext = SpSession.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Load Data\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "#Load the CSV file into a RDD\n",
    "bankData = SpContext.textFile(\"bank.csv\")\n",
    "bankData.cache()\n",
    "bankData.count()\n",
    "\n",
    "#Remove the first line (contains headers)\n",
    "firstLine=bankData.first()\n",
    "dataLines = bankData.filter(lambda x: x != firstLine)\n",
    "dataLines.count()\n",
    "\n",
    "\"\"\"--------------------------------------------------------------------------\n",
    "Cleanup Data\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "# Change labels to numeric ones and build a Row object\n",
    "\n",
    "import math\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def transformToNumeric( inputStr) :\n",
    "    \n",
    "    attList=inputStr.replace(\"\\\"\",\"\").split(\";\")\n",
    "    \n",
    "    age=float(attList[0])\n",
    "    #convert outcome to float    \n",
    "    outcome = 0.0 if attList[16] == \"no\" else 1.0\n",
    "    \n",
    "    #create indicator variables for single/married    \n",
    "    single= 1.0 if attList[2] == \"single\" else 0.0\n",
    "    married = 1.0 if attList[2] == \"married\" else 0.0\n",
    "    divorced = 1.0 if attList[2] == \"divorced\" else 0.0\n",
    "    \n",
    "    #create indicator variables for education\n",
    "    primary = 1.0 if attList[3] == \"primary\" else 0.0\n",
    "    secondary = 1.0 if attList[3] == \"secondary\" else 0.0\n",
    "    tertiary = 1.0 if attList[3] == \"tertiary\" else 0.0\n",
    "    \n",
    "    #convert default to float\n",
    "    default= 0.0 if attList[4] == \"no\" else 1.0\n",
    "    #convert balance amount to float\n",
    "    balance=float(attList[5])\n",
    "    #convert loan to float\n",
    "    loan= 0.0 if attList[7] == \"no\" else 1.0\n",
    "    \n",
    "    #Create a row with cleaned up and converted data\n",
    "    values= Row(     OUTCOME=outcome ,\\\n",
    "                    AGE=age, \\\n",
    "                    SINGLE=single, \\\n",
    "                    MARRIED=married, \\\n",
    "                    DIVORCED=divorced, \\\n",
    "                    PRIMARY=primary, \\\n",
    "                    SECONDARY=secondary, \\\n",
    "                    TERTIARY=tertiary, \\\n",
    "                    DEFAULT=default, \\\n",
    "                    BALANCE=balance, \\\n",
    "                    LOAN=loan                    \n",
    "                    ) \n",
    "    return values\n",
    "    \n",
    "#Change to a Vector\n",
    "bankRows = dataLines.map(transformToNumeric)\n",
    "bankRows.collect()[:15]\n",
    "\n",
    "bankData = SpSession.createDataFrame(bankRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+\n",
      "|summary|               AGE|           BALANCE|             DEFAULT|           DIVORCED|               LOAN|           MARRIED|            OUTCOME|            PRIMARY|         SECONDARY|             SINGLE|           TERTIARY|\n",
      "+-------+------------------+------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+\n",
      "|  count|               541|               541|                 541|                541|                541|               541|                541|                541|               541|                541|                541|\n",
      "|   mean| 41.26987060998152|1444.7818853974122|0.022181146025878003|0.10905730129390019|0.16266173752310537|0.6155268022181146| 0.3974121996303142| 0.1534195933456562|0.4953789279112754| 0.2754158964879852| 0.3142329020332717|\n",
      "| stddev|10.555374170161665|2423.2722735171933| 0.14740864244029794|0.31199958221618496| 0.3693983273588202|0.4869207382098542|0.48981549262335145|0.36072502544980206| 0.500441374299428|0.44713704797607595|0.46463926002059763|\n",
      "|    min|              19.0|           -1206.0|                 0.0|                0.0|                0.0|               0.0|                0.0|                0.0|               0.0|                0.0|                0.0|\n",
      "|    max|              78.0|           16873.0|                 1.0|                1.0|                1.0|               1.0|                1.0|                1.0|               1.0|                1.0|                1.0|\n",
      "+-------+------------------+------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+\n",
      "\n",
      "('Correlation to OUTCOME for ', 'AGE', -0.18232104327365217)\n",
      "('Correlation to OUTCOME for ', 'BALANCE', 0.03657486611997679)\n",
      "('Correlation to OUTCOME for ', 'DEFAULT', -0.04536965206737377)\n",
      "('Correlation to OUTCOME for ', 'DIVORCED', -0.07812659940926989)\n",
      "('Correlation to OUTCOME for ', 'LOAN', -0.030420586112717283)\n",
      "('Correlation to OUTCOME for ', 'MARRIED', -0.37532412991335645)\n",
      "('Correlation to OUTCOME for ', 'OUTCOME', 1.0)\n",
      "('Correlation to OUTCOME for ', 'PRIMARY', -0.1256154883267798)\n",
      "('Correlation to OUTCOME for ', 'SECONDARY', 0.026392774894072955)\n",
      "('Correlation to OUTCOME for ', 'SINGLE', 0.463232849343605)\n",
      "('Correlation to OUTCOME for ', 'TERTIARY', 0.08494840766635611)\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[30.0,1787.0,0.0,...|\n",
      "|  1.0|[33.0,4789.0,0.0,...|\n",
      "|  1.0|[35.0,1350.0,0.0,...|\n",
      "|  1.0|[30.0,1476.0,0.0,...|\n",
      "|  0.0|[59.0,0.0,0.0,0.0...|\n",
      "|  1.0|[35.0,747.0,0.0,0...|\n",
      "|  1.0|[36.0,307.0,0.0,0...|\n",
      "|  0.0|[39.0,147.0,0.0,0...|\n",
      "|  0.0|[41.0,221.0,0.0,0...|\n",
      "|  1.0|[43.0,-88.0,0.0,0...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Data Analytics\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "#See descriptive analytics.\n",
    "bankData.describe().show()\n",
    "\n",
    "#Find correlation between predictors and target\n",
    "for i in bankData.columns:\n",
    "    if not( isinstance(bankData.select(i).take(1)[0][0], str)) :\n",
    "        print( \"Correlation to OUTCOME for \", i, \\\n",
    "            bankData.stat.corr('OUTCOME',i))\n",
    "\n",
    "\"\"\"--------------------------------------------------------------------------\n",
    "Prepare data for ML\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "#Transform to a Data Frame for input to Machine Learing\n",
    "\n",
    "def transformToLabeledPoint(row) :\n",
    "    lp = ( row[\"OUTCOME\"], \\\n",
    "            Vectors.dense([\n",
    "                row[\"AGE\"], \\\n",
    "                row[\"BALANCE\"], \\\n",
    "                row[\"DEFAULT\"], \\\n",
    "                row[\"DIVORCED\"], \\\n",
    "                row[\"LOAN\"], \\\n",
    "                row[\"MARRIED\"], \\\n",
    "                row[\"PRIMARY\"], \\\n",
    "                row[\"SECONDARY\"], \\\n",
    "                row[\"SINGLE\"], \\\n",
    "                row[\"TERTIARY\"]\n",
    "        ]))\n",
    "    return lp\n",
    "    \n",
    "bankLp = bankData.rdd.map(transformToLabeledPoint)\n",
    "bankLp.collect()\n",
    "bankDF = SpSession.createDataFrame(bankLp,[\"label\", \"features\"])\n",
    "bankDF.select(\"label\",\"features\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------+\n",
      "|label|pcaFeatures                                                  |\n",
      "+-----+-------------------------------------------------------------+\n",
      "|0.0  |[-1787.0188971973814,28.86209683775569,-0.06459982604876238] |\n",
      "|1.0  |[-4789.020177138494,29.92256263634302,-0.9830243513096398]   |\n",
      "|1.0  |[-1350.0222131632624,34.101108097967185,0.8951427168301703]  |\n",
      "|1.0  |[-1476.018951718456,29.051333993597034,0.395272386802192]    |\n",
      "|0.0  |[-0.037889185366468646,58.98971820001771,-0.7290792383661894]|\n",
      "|1.0  |[-747.0223377634925,34.488291981817895,0.9045654956970107]   |\n",
      "|1.0  |[-307.0230691022594,35.79985053965531,0.5170631523785959]    |\n",
      "|0.0  |[-147.02501216176347,38.90107856650334,-0.8069627548799411]  |\n",
      "|0.0  |[-221.02629853487875,40.853633675695,0.5373036365803205]     |\n",
      "|1.0  |[87.97238687688711,43.06265944115104,-0.06701642871171584]   |\n",
      "|0.0  |[-9374.023105550945,32.976458837994976,-0.9511484606914444]  |\n",
      "|0.0  |[-264.0275573152839,42.824803639813595,-0.7936737710234684]  |\n",
      "|0.0  |[-1109.0229033818869,35.284889553173926,0.5045307002207087]  |\n",
      "|1.0  |[-502.0127364032962,19.649271797807735,-0.48615993820207115] |\n",
      "|1.0  |[-360.019807655108,30.76698063761417,-0.9213732295769705]    |\n",
      "|0.0  |[-194.02563994730266,39.87162681803845,0.45309876904012364]  |\n",
      "|0.0  |[-4073.035120568307,53.375323491665426,-0.8040639317646903]  |\n",
      "|1.0  |[-2317.0232980131423,35.47962642487377,0.887590534462346]    |\n",
      "|0.0  |[220.98389763132965,25.12353896656825,0.34603890246559277]   |\n",
      "|1.0  |[-132.01987660190267,30.913009397389757,-0.8369629258629329] |\n",
      "+-----+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+----------+-----+\n",
      "|indexed|prediction|count|\n",
      "+-------+----------+-----+\n",
      "|    1.0|       1.0|   28|\n",
      "|    0.0|       1.0|   13|\n",
      "|    1.0|       0.0|   38|\n",
      "|    0.0|       0.0|   92|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Machine Learning\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#Perform PCA\n",
    "from pyspark.ml.feature import PCA\n",
    "bankPCA = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "pcaModel = bankPCA.fit(bankDF)\n",
    "pcaResult = pcaModel.transform(bankDF).select(\"label\",\"pcaFeatures\")\n",
    "pcaResult.show(truncate=False)\n",
    "\n",
    "#Indexing needed as pre-req for Decision Trees\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    "si_model = stringIndexer.fit(pcaResult)\n",
    "td = si_model.transform(pcaResult)\n",
    "td.collect()\n",
    "\n",
    "#Split into training and testing data\n",
    "(trainingData, testData) = td.randomSplit([0.7, 0.3])\n",
    "trainingData.count()\n",
    "testData.count()\n",
    "testData.collect()\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "#Create the model\n",
    "rmClassifer = RandomForestClassifier(labelCol=\"indexed\", \\\n",
    "                featuresCol=\"pcaFeatures\")\n",
    "rmModel = rmClassifer.fit(trainingData)\n",
    "\n",
    "#Predict on the test data\n",
    "predictions = rmModel.transform(testData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"pcaFeatures\").collect()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
    "                    labelCol=\"indexed\",metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)      \n",
    "\n",
    "#Draw a confusion matrix\n",
    "predictions.groupBy(\"indexed\",\"prediction\").count().show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
