{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run command export PYSPARK_SUBMIT_ARGS=\"--master spark://127.0.0.0\"\n",
    "spark2 = SparkSession.builder.appName('ml').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Spark Session\n",
    "SpSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"ml\") \\\n",
    "    .config(\"spark.executor.memory\", \"0.1g\") \\\n",
    "    .config(\"spark.cores.max\",\"2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/home/sushant/Projects/Spark_Project/temp\")\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "#Get the Spark Context from Spark Session    \n",
    "SpContext = SpSession.sparkContext\n",
    "\n",
    "#Test Spark\n",
    "testData = SpContext.parallelize([3,6,4,2])\n",
    "testData.count()\n",
    "#check http://localhost:4040 to see if Spark is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoData = SpContext.textFile(\"auto-miles-per-gallon.csv\")\n",
    "autoData.cache()\n",
    "autoData.take(5)\n",
    "# Remove header\n",
    "dataLines = autoData.filter(lambda x: \"CYLINDERS\" not in x)\n",
    "dataLines.count()\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\"\"\"--------------------------------------------------------------------------\n",
    "Cleanup Data\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "#Use default for average HP\n",
    "avgHP =SpContext.broadcast(80.0)\n",
    "\n",
    "#Function to cleanup Data\n",
    "def CleanupData( inputStr) :\n",
    "    global avgHP\n",
    "    attList=inputStr.split(\",\")\n",
    "    \n",
    "    #Replace ? values with a normal value\n",
    "    hpValue = attList[3]\n",
    "    if hpValue == \"?\":\n",
    "        hpValue=avgHP.value\n",
    "       \n",
    "    #Create a row with cleaned up and converted data\n",
    "    values= Row(     MPG=float(attList[0]),\\\n",
    "                     CYLINDERS=float(attList[1]), \\\n",
    "                     DISPLACEMENT=float(attList[2]), \n",
    "                     HORSEPOWER=float(hpValue),\\\n",
    "                     WEIGHT=float(attList[4]), \\\n",
    "                     ACCELERATION=float(attList[5]), \\\n",
    "                     MODELYEAR=float(attList[6])\n",
    "                       ) \n",
    "    return values\n",
    "\n",
    "#Run map for cleanup\n",
    "autoMap = dataLines.map(CleanupData)\n",
    "autoMap.cache()\n",
    "autoMap.take(5)\n",
    "#Create a Data Frame with the data. \n",
    "autoDf = SpSession.createDataFrame(autoMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|               MPG|         CYLINDERS|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               398|               398|\n",
      "|   mean|23.514572864321615| 5.454773869346734|\n",
      "| stddev| 7.815984312565783|1.7010042445332123|\n",
      "|    min|               9.0|               3.0|\n",
      "|    max|              46.6|               8.0|\n",
      "+-------+------------------+------------------+\n",
      "\n",
      "('Correlation to MPG for ', 'ACCELERATION', 0.42028891210165054)\n",
      "('Correlation to MPG for ', 'CYLINDERS', -0.7753962854205539)\n",
      "('Correlation to MPG for ', 'DISPLACEMENT', -0.8042028248058979)\n",
      "('Correlation to MPG for ', 'HORSEPOWER', -0.7746308409203806)\n",
      "('Correlation to MPG for ', 'MODELYEAR', 0.5792671330833092)\n",
      "('Correlation to MPG for ', 'MPG', 1.0)\n",
      "('Correlation to MPG for ', 'WEIGHT', -0.8317409332443344)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Data Analytics\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "#See descriptive analytics.\n",
    "autoDf.select(\"MPG\",\"CYLINDERS\").describe().show()\n",
    "\n",
    "\n",
    "#Find correlation between predictors and target\n",
    "for i in autoDf.columns:\n",
    "    if not( isinstance(autoDf.select(i).take(1)[0][0], str)) :\n",
    "        print( \"Correlation to MPG for \", i, autoDf.stat.corr('MPG',i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|label|           features|\n",
      "+-----+-------------------+\n",
      "| 18.0|[12.0,307.0,3504.0]|\n",
      "| 15.0|[11.5,350.0,3693.0]|\n",
      "| 18.0|[11.0,318.0,3436.0]|\n",
      "| 16.0|[12.0,304.0,3433.0]|\n",
      "| 17.0|[10.5,302.0,3449.0]|\n",
      "| 15.0|[10.0,429.0,4341.0]|\n",
      "| 14.0| [9.0,454.0,4354.0]|\n",
      "| 14.0| [8.5,440.0,4312.0]|\n",
      "| 14.0|[10.0,455.0,4425.0]|\n",
      "| 15.0| [8.5,390.0,3850.0]|\n",
      "+-----+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''--------------------------------------------------------------------------\n",
    "Prepare data for ML\n",
    "-------------------------------------------------------------------------'''\n",
    "\n",
    "#Transform to a Data Frame for input to Machine Learing\n",
    "#Drop columns that are not required (low correlation)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "def transformToLabeledPoint(row) :\n",
    "    lp = ( row[\"MPG\"], Vectors.dense([row[\"ACCELERATION\"],\\\n",
    "                        row[\"DISPLACEMENT\"], \\\n",
    "                        row[\"WEIGHT\"]]))\n",
    "    return lp\n",
    "    \n",
    "autoLp = autoMap.map(transformToLabeledPoint)\n",
    "autoDF = SpSession.createDataFrame(autoLp,[\"label\", \"features\"])\n",
    "autoDF.select(\"label\",\"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.13121280656751166,-0.014334819573204522,-0.005777197029317336]\n",
      "Intercept: 41.4094590992\n",
      "+------------------+-----+-------------------+\n",
      "|        prediction|label|           features|\n",
      "+------------------+-----+-------------------+\n",
      "|13.695847388400853| 10.0|[15.0,307.0,4376.0]|\n",
      "| 15.63149889077511| 14.0|[14.5,302.0,4042.0]|\n",
      "|14.491944696892986| 14.0|[15.5,304.0,4257.0]|\n",
      "|10.216522812545879| 16.0|[11.5,400.0,4668.0]|\n",
      "|19.090126557002506| 16.0|[18.0,258.0,3632.0]|\n",
      "| 19.12357062854149| 16.5|[16.7,168.0,3820.0]|\n",
      "|17.318536261844443| 17.6|[13.4,302.0,3725.0]|\n",
      "|22.370390937091322| 18.0|[13.5,258.0,2962.0]|\n",
      "|23.671406928330903| 19.0|[21.9,120.0,3270.0]|\n",
      "|18.982448350606532| 19.2|[13.2,305.0,3425.0]|\n",
      "| 21.79583876702373| 19.4|[17.2,232.0,3210.0]|\n",
      "| 25.26841376652021| 20.3|[15.9,131.0,2830.0]|\n",
      "|24.563686374686245| 22.0|[14.5,121.0,2945.0]|\n",
      "|28.282358160866544| 22.0|[16.5,108.0,2379.0]|\n",
      "| 27.53023470839626| 22.0|[18.0,121.0,2511.0]|\n",
      "|28.672212998084355| 23.0|[14.0,122.0,2220.0]|\n",
      "|23.893589555602777| 23.0|[16.0,198.0,2904.0]|\n",
      "| 27.73963031880954| 24.0|[14.5,107.0,2430.0]|\n",
      "| 29.96011101808623| 25.0| [17.0,97.5,2126.0]|\n",
      "| 25.02374853855434| 26.8|[12.9,173.0,2700.0]|\n",
      "+------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6479532399744575"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"--------------------------------------------------------------------------\n",
    "Perform Machine Learning\n",
    "-------------------------------------------------------------------------\"\"\"\n",
    "\n",
    "#Split into training and testing data\n",
    "(trainingData, testData) = autoDF.randomSplit([0.9, 0.1])\n",
    "trainingData.count()\n",
    "testData.count()\n",
    "\n",
    "#Build the model on training data\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "#Print the metrics\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "#Predict on the test data\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.select(\"prediction\",\"label\",\"features\").show()\n",
    "\n",
    "#Find R2 for Linear Regression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"r2\")\n",
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
