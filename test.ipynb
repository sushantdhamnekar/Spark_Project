{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark1 = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Spark Session\n",
    "SpSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"test\") \\\n",
    "    .config(\"spark.executor.memory\", \"0.1g\") \\\n",
    "    .config(\"spark.cores.max\",\"2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/home/sushant/Projects/Spark_Project/temp\")\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "#Get the Spark Context from Spark Session    \n",
    "SpContext = SpSession.sparkContext\n",
    "\n",
    "#Test Spark\n",
    "testData = SpContext.parallelize([3,6,4,2])\n",
    "testData.count()\n",
    "#check http://localhost:4040 to see if Spark is running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'positive,The Da Vinci Code book is just awesome.',\n",
       " u'positive,i liked the Da Vinci Code a lot.',\n",
       " u'positive,i liked the Da Vinci Code a lot.',\n",
       " u\"positive,I liked the Da Vinci Code but it ultimatly didn't seem to hold it's own.\",\n",
       " u\"positive,that's not even an exaggeration ) and at midnight we went to Wal-Mart to buy the Da Vinci Code\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[u'POSITIVE,THE DA VINCI CODE BOOK IS JUST AWESOME.',\n",
       " u'POSITIVE,I LIKED THE DA VINCI CODE A LOT.',\n",
       " u'POSITIVE,I LIKED THE DA VINCI CODE A LOT.',\n",
       " u\"POSITIVE,I LIKED THE DA VINCI CODE BUT IT ULTIMATLY DIDN'T SEEM TO HOLD IT'S OWN.\",\n",
       " u\"POSITIVE,THAT'S NOT EVEN AN EXAGGERATION ) AND AT MIDNIGHT WE WENT TO WAL-MART TO BUY THE DA VINCI CODE\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'positive,The Da Vinci Code book is just awesome.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spark has a lazy execution\n",
    "tweetsRDD = SpContext.textFile('movietweets.csv')\n",
    "display(tweetsRDD.take(5))\n",
    "ucrRDD = tweetsRDD.map(lambda x: x.upper())\n",
    "display(ucrRDD.take(5))\n",
    "tweetsRDD.count()\n",
    "tweetsRDD.collect() # only for small dataset\n",
    "tweetsRDD.first()\n",
    "autoData = SpContext.textFile(\"auto-data.csv\")\n",
    "autoData.cache()\n",
    "print autoData.take(5)\n",
    "autoData.count()\n",
    "#for line in autoData.collect():\n",
    "    #print line\n",
    "# Save loaded data to normal file\n",
    "autoDataFile = open(\"auto-Data-save.csv\",\"w\")\n",
    "autoDataFile.write('\\n'.join(autoData.collect()))\n",
    "autoDataFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformation\n",
    "tsvData = autoData.map(lambda x: x.replace(\",\",\"\\t\"))\n",
    "tsvData.take(5)\n",
    "toyotaData = autoData.filter(lambda x: \"toyota\" in x)\n",
    "toyotaData.count()\n",
    "words = toyotaData.flatMap(lambda line : line.split(','))\n",
    "words.take(20)\n",
    "words.count()\n",
    "for x in testData.distinct().collect():\n",
    "    print x\n",
    "word1 = SpContext.parallelize(['hey','where','are','you'])\n",
    "word2 = SpContext.parallelize(['I', 'hey','am','coming'])\n",
    "for intersects in word1.union(word2).distinct().collect():\n",
    "    print intersects\n",
    "for intersects in word1.intersection(word2).distinct().collect():\n",
    "    print intersects\n",
    "\n",
    "#pass a function to be worked on whole data\n",
    "def cleansingRDD(autostr):\n",
    "    if isinstance(autostr,int):\n",
    "        return autostr\n",
    "    attlist = autostr.split(\",\")\n",
    "    attlist[5] = attlist[5].upper()\n",
    "    return \",\".join(attlist)\n",
    "    \n",
    "cleanedRDD = autoData.map(cleansingRDD)\n",
    "cleanedRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce operations on RDD\n",
    "testData.collect()\n",
    "testData.reduce(lambda x, y: x+y)\n",
    "autoData.reduce(lambda x,y : y if len(x)> len(y) else x)\n",
    "\n",
    "#Find average MPG for all cars\n",
    "\n",
    "def getMPG(autostr):\n",
    "    if isinstance(autostr, int):\n",
    "        return autostr\n",
    "    attlist = autostr.split(\",\")\n",
    "    if attlist[9].isdigit():\n",
    "        return int(attlist[9])\n",
    "    else:\n",
    "        return 0\n",
    "autoData.reduce(lambda x,y : getMPG(x)+getMPG(y))/(autoData.count()-1) # -1 to reduce the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keyvalue pair\n",
    "kpairData = autoData.map(lambda x:(x.split(',')[0],x.split(',')[7]))\n",
    "kpairData.take(5)\n",
    "kpairData.keys().collect()\n",
    "header = kpairData.first()\n",
    "kpairData = kpairData.filter(lambda line: line !=header)\n",
    "\n",
    "# Find average mpg for every brand\n",
    "addOne = kpairData.mapValues(lambda x : (x,1))\n",
    "brandValues = addOne.reduceByKey(lambda x,y:(int(x[0])+int(y[0]),x[1]+y[1]))\n",
    "averageBrand = brandValues.mapValues(lambda x: int(x[0])/int(x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accumulator, broadcast, persistance of variables\n",
    "\n",
    "sedanCount = SpContext.accumulator(0)\n",
    "hatchbackCount = SpContext.accumulator(0)\n",
    "\n",
    "sedanText = SpContext.broadcast(\"sedan\")\n",
    "hatchbackText = SpContext.broadcast(\"hatchback\")\n",
    "\n",
    "def splitlines(line):\n",
    "    global sedanCount\n",
    "    global hatchbackCount\n",
    "    \n",
    "    if sedanText.value in line:\n",
    "        sedanCount += 1\n",
    "    elif hatchbackText.value in line:\n",
    "        hatchbackCount += 1\n",
    "        \n",
    "    return line.split(',')\n",
    "\n",
    "autoTypeCount = autoData.map(splitlines)\n",
    "autoTypeCount.count()\n",
    "print hatchbackCount, sedanCount\n",
    "\n",
    "testData.getNumPartitions()\n",
    "\n",
    "newRDD = SpContext.parallelize([1,2,3,4,5],3)\n",
    "newRDD.cache()\n",
    "newRDD.collect()\n",
    "newRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
